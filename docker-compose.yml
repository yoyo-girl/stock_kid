version: '2'
services:
#   jupyter:
#     build:
#       context: ./dockerfile
#       dockerfile: dockerfile-jupyter
#     container_name: jupyter
#     hostname: jupyter
#     ports:
#       - "8888:8888"
#     command: start-notebook.sh --NotebookApp.token=''
#     volumes:
#       - ./jupyter:/home/jovyan/Project
#     restart: always

#   mysql:
#     image: mysql:8.0
#     container_name: mysql
#     hostname: mysql
#     ports:
#       - "3307:3306"
#     environment:
#       - MYSQL_ROOT_PASSWORD=iii
#     volumes:
#       - ./mysql_db/mysql_data:/var/lib/mysql
#       - ./mysql_db/mysql_init:/docker-entrypoint-initdb.d/
#     restart: always

#   pyspark:
#     image: orozcohsu/pyspark_mongo_ltu:v3  
#     container_name: pyspark
#     hostname: pyspark
#     ports:
#       - "8890:8888"
#       - "4040:4040"
#       - "4041:4041"
#     command: start-notebook.sh --NotebookApp.token=''
#     volumes:
#       - ./pyspark:/pyspark
#     restart: always

#   mongo:
#     image: mongo
#     container_name: mongodb
#     hostname: mongodb
#     volumes:
#       - ./mongodb:/data/db
#     restart: always
#     expose:
#       - 6016
#     ports:
#       - "27017:27017"


#   zookeeper:
#     image: wurstmeister/zookeeper
#     container_name: zookeeper
#     hostname: zookeeper
#     ports:
#       - "2181:2181"

#   kafka:
#     image: wurstmeister/kafka:2.11-0.11.0.3
#     container_name: kafka
#     hostname: kafka
#     ports:
#       - "9092:9092"
#     depends_on:
#       - zookeeper
#     environment:
#       KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
#       KAFKA_ADVERTISED_HOST_NAME: 192.168.99.100
#       KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://:9092
#     volumes:
#       - /var/run:/var/run/docker.sock

#   restproxy:
#     image: confluentinc/cp-kafka-rest:5.2.1
#     restart: always
#     container_name: restproxy
#     hostname: restproxy
#     depends_on:
#       - kafka
#     environment:
#       KAFKA_REST_ZOOKEEPER_CONNECT: zookeeper:2181
#       KAFKA_REST_LISTENERS: http://0.0.0.0:8082
#       KAFKA_REST_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
#       KAFKA_REST_HOST_NAME: restproxy
#       KAFKA_REST_DEBUG: "true"
#     ports:
#       - 8082:8082

#   elasticsearch:
#     image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.2.0
#     container_name: elasticsearch
#     hostname: elasticsearch
#     restart: unless-stopped
#     environment:
#       - cluster.name=docker-cluster
#       - node.name=node1
#       - bootstrap.memory_lock=true
#       - "ES_JAVA_OPTS=-Xms384m -Xmx384m"
#       - "cluster.initial_master_nodes=node1"
#     ulimits:
#       memlock:
#         soft: -1
#         hard: -1
#     volumes:
#       - ./esdata:/usr/share/elasticsearch/data
#     ports:
#       - 9200:9200

  # logstash:
  #   image: docker.elastic.co/logstash/logstash-oss:7.2.0
  #   container_name: logstash
  #   hostname: logstash
  #   restart: always
  #   volumes:
  #     - ./logstash/data:/usr/share/logstash/data:rw
  #     - ./logstash/template:/usr/share/logstash/template:ro
  #     #- ./logstash/logs:/usr/share/logstash/logs:rw
  #     - ./logstash/config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro
  #     - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
  #   ports:
  #     - "127.0.0.1:5000:5000/udp"
  #   environment:
  #     LS_JAVA_OPTS: "-Xmx256m -Xms256m"
  #   depends_on:
  #     - elasticsearch


#   kibana:
#     image: docker.elastic.co/kibana/kibana-oss:7.2.0
#     container_name: kibana
#     hostname: kibana
#     environment:
#       SERVER_NAME: kibana_server
#       ELASTICSEARCH_HOSTS: http://elasticsearch:9200
#     depends_on:
#       - elasticsearch
#     ports:
#       - 5601:5601

  redis:
    image: redis 
    container_name: redis
    hostname: redis
    environment:          
      - ENV=develop
    ports:
      - 6379:6379

